{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Processing c:\\users\\何佳馨\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\\termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Processing c:\\users\\何佳馨\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\\wrapt-1.12.1-cp38-cp38-win_amd64.whl\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-57.4.0-py3-none-any.whl (819 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30710 sha256=49f164202a1ca43e73a247cfc4da0508fd1474d1d0d296dab4b5fca040440464\n",
      "  Stored in directory: c:\\users\\何佳馨\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built clang\n",
      "Installing collected packages: termcolor, numpy, opt-einsum, wrapt, flatbuffers, wheel, six, astunparse, grpcio, tensorflow-estimator, protobuf, google-pasta, absl-py, keras, typing-extensions, clang, gast, h5py, keras-preprocessing, tensorboard-plugin-wit, werkzeug, setuptools, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, markdown, certifi, idna, charset-normalizer, urllib3, requests, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9f40bbb0d77d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output\n",
    "!pip3 install --ignore-installed --upgrade --ignore-installed tensorflow\n",
    "clear_output()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.6.0-cp38-cp38-win_amd64.whl (423.3 MB)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (0.12.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Processing c:\\users\\何佳馨\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\\clang-5.0-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.5.0 requires grpcio~=1.34.0, but you'll have grpcio 1.39.0 which is incompatible.\n",
      "tensorflow 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you'll have tensorflow-estimator 2.6.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Using cached grpcio-1.39.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras~=2.6 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.19.2)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (3.17.3)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.4.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.31.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\amy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\amy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\amy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\amy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Installing collected packages: grpcio, tensorboard, clang, tensorflow-estimator, tensorflow-gpu\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "Successfully installed clang-5.0 grpcio-1.39.0 tensorboard-2.6.0 tensorflow-estimator-2.6.0 tensorflow-gpu-2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.0.0-beta0 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0)\n",
      "ERROR: No matching distribution found for tensorflow-gpu==2.0.0-beta0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\amy\\anaconda3\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-gpu\n",
    "!pip install tensorflow-gpu==2.0.0-beta0\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow_datasets) (0.12.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (20.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.24.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\何佳馨\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow_datasets) (3.17.3)\n",
      "Requirement already satisfied: six in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.50.2)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.2.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: future in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\amy\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.19.2)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\amy\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\amy\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\amy\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\amy\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\amy\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.4.0)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21500 sha256=48f546c35b73569870f05ec2c6dc3370218dd77ff0111e8f19ebba8bacce2a06\n",
      "  Stored in directory: c:\\users\\何佳馨\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built promise\n",
      "Installing collected packages: googleapis-common-protos, tensorflow-metadata, promise, dill, importlib-resources, tensorflow-datasets\n",
      "Successfully installed dill-0.3.4 googleapis-common-protos-1.53.0 importlib-resources-5.2.2 promise-2.3 tensorflow-datasets-4.4.0 tensorflow-metadata-1.2.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"nmt\"\n",
    "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
    "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "download_dir = \"tensorflow-datasets/downloads\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
    "\n",
    "config = tfds.translate.wmt.WmtConfig(\n",
    "  version=tfds.core.Version('0.0.3', experiments={tfds.core.ReadInstruction: False}),\n",
    "  language_pair=(\"zh\", \"en\"),\n",
    "  subsets={\n",
    "    tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
    "  }\n",
    ")\n",
    "builder = tfds.builder(\"wmt_translate\", config=config)\n",
    "builder.download_and_prepare(download_dir=download_dir)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train[:20%]', 'train[20%:21%]', 'train[21%:]']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = ['train[:20%]','train[20%:21%]','train[21%:]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = builder.as_dataset(split=split, as_supervised=True)\n",
    "train_examples, val_examples, _ = examples\n",
    "\n",
    "sample_examples = []\n",
    "num_samples = 10\n",
    "\n",
    "for en_t, zh_t in train_examples.take(num_samples):\n",
    "  en = en_t.numpy().decode(\"utf-8\")\n",
    "  zh = zh_t.numpy().decode(\"utf-8\")\n",
    "\n",
    "    # 之後用來簡單評估模型的訓練情況\n",
    "  sample_examples.append((en, zh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有已建立的字典，從頭建立。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  subword_encoder_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
    "  print(f\"載入已建立的字典： {en_vocab_file}\")\n",
    "except:\n",
    "  print(\"沒有已建立的字典，從頭建立。\")\n",
    "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "      (en.numpy() for en, _ in train_examples), \n",
    "      target_vocab_size=2**13) # 有需要可以調整字典大小\n",
    " \n",
    "  # 將字典檔案存下以方便下次 warmstart\n",
    "  subword_encoder_en.save_to_file(en_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有已建立的字典，從頭建立。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  subword_encoder_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
    "  print(f\"載入已建立的字典： {zh_vocab_file}\")\n",
    "except:\n",
    "  print(\"沒有已建立的字典，從頭建立。\")\n",
    "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "      (zh.numpy() for _, zh in train_examples), \n",
    "      target_vocab_size=2**13, # 有需要可以調整字典大小\n",
    "      max_subword_length=1) # 每一個中文字就是字典裡的一個單位\n",
    "  \n",
    "  # 將字典檔案存下以方便下次 warmstart \n",
    "  subword_encoder_zh.save_to_file(zh_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(en_t, zh_t):\n",
    "  # 因為字典的索引從 0 開始，\n",
    "  # 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值\n",
    "  # 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值\n",
    "  en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(\n",
    "      en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
    "  # 同理，不過是使用中文字典的最後一個索引 + 1\n",
    "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
    "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
    "  \n",
    "  return en_indices, zh_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_t, zh_t = next(iter(train_examples))\n",
    "en_indices, zh_indices = encode(en_t, zh_t)\n",
    "\n",
    "def tf_encode(en_t, zh_t):\n",
    "  # 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors\n",
    "  # 要到 `tf.py_funtion` 裡頭才是\n",
    "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
    "  return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
    "\n",
    "# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，\n",
    "# 我們會從頭建立一個正式的 `train_dataset`\n",
    "tmp_dataset = train_examples.map(tf_encode)\n",
    "en_indices, zh_indices = next(iter(tmp_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
    "  # en, zh 分別代表英文與中文的索引序列\n",
    "  return tf.logical_and(tf.size(en) <= max_length,\n",
    "                        tf.size(zh) <= max_length)\n",
    "\n",
    "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
    "tmp_dataset = tmp_dataset.filter(filter_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 0\n",
    "for en_indices, zh_indices in tmp_dataset:\n",
    "  cond1 = len(en_indices) <= MAX_LENGTH\n",
    "  cond2 = len(zh_indices) <= MAX_LENGTH\n",
    "  assert cond1 and cond2\n",
    "  num_examples += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
    "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "en_batch, zh_batch = next(iter(tmp_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 15000\n",
    "\n",
    "# 訓練集\n",
    "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
    "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
    "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
    "                 .cache() # 加快讀取數據\n",
    "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
    "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
    "                               padded_shapes=([-1], [-1]))\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
    "# 驗證集\n",
    "val_dataset = (val_examples\n",
    "               .map(tf_encode)\n",
    "               .filter(filter_max_length)\n",
    "               .padded_batch(BATCH_SIZE, \n",
    "                             padded_shapes=([-1], [-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_batch, zh_batch = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_examples = [\n",
    "    (\"It is important.\", \"这很重要。\"),\n",
    "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
    "]\n",
    "\n",
    "batch_size = 2\n",
    "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
    "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
    "))\n",
    "\n",
    "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
    "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
    "demo_dataset = demo_examples.map(tf_encode)\\\n",
    "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
    "\n",
    "# 取出這個 demo dataset 裡唯一一個 batch\n",
    "inp, tar = next(iter(demo_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
       " array([[[ 0.03923363, -0.00596677,  0.04476615,  0.03714598],\n",
       "         [ 0.03783781,  0.04554163,  0.02143342, -0.03304566],\n",
       "         [-0.01816959, -0.04141357,  0.04854757, -0.04469186],\n",
       "         [-0.01209208,  0.00200089,  0.02259952,  0.03432972],\n",
       "         [-0.01479573,  0.02315576, -0.01417556,  0.04024959],\n",
       "         [ 0.02121812, -0.04504773,  0.01966575, -0.03497748],\n",
       "         [ 0.00530351, -0.00330327,  0.03301643,  0.04337558],\n",
       "         [ 0.00530351, -0.00330327,  0.03301643,  0.04337558]],\n",
       " \n",
       "        [[ 0.03923363, -0.00596677,  0.04476615,  0.03714598],\n",
       "         [ 0.04340663, -0.02604903,  0.03771168, -0.04120665],\n",
       "         [-0.02922045, -0.01890837,  0.01422188, -0.01134964],\n",
       "         [-0.03066036, -0.02007837,  0.02598066,  0.01638466],\n",
       "         [-0.02036192, -0.03742052, -0.02103468, -0.03075155],\n",
       "         [-0.03845371,  0.03787264, -0.03780406, -0.00748882],\n",
       "         [-0.01479573,  0.02315576, -0.01417556,  0.04024959],\n",
       "         [ 0.02121812, -0.04504773,  0.01966575, -0.03497748]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
       " array([[[-0.0482867 , -0.04924861, -0.02495612, -0.02124604],\n",
       "         [-0.04534279, -0.00497727,  0.01638568,  0.0061962 ],\n",
       "         [ 0.03681939, -0.0237577 , -0.0231926 , -0.02994195],\n",
       "         [-0.01866832,  0.02319982,  0.0019088 , -0.01218827],\n",
       "         [-0.02615886, -0.04035451, -0.04153559,  0.03893144],\n",
       "         [-0.03842498,  0.00823998,  0.04053162, -0.0392449 ],\n",
       "         [ 0.04079253,  0.04012421, -0.04018716,  0.00984683],\n",
       "         [ 0.04835805, -0.02670898,  0.02625997, -0.02681632],\n",
       "         [ 0.04835805, -0.02670898,  0.02625997, -0.02681632],\n",
       "         [ 0.04835805, -0.02670898,  0.02625997, -0.02681632]],\n",
       " \n",
       "        [[-0.0482867 , -0.04924861, -0.02495612, -0.02124604],\n",
       "         [-0.01072525,  0.02462658,  0.02211083, -0.02654784],\n",
       "         [-0.04658234,  0.03867486, -0.03802537, -0.03682441],\n",
       "         [ 0.00496525, -0.04902137,  0.03112253, -0.00256998],\n",
       "         [ 0.00831871, -0.04760573, -0.03867432,  0.02406497],\n",
       "         [-0.02954409, -0.03097274,  0.00352777,  0.02857602],\n",
       "         [-0.00087429, -0.04430662,  0.00890751,  0.02293241],\n",
       "         [ 0.02807664,  0.03353207,  0.01488367,  0.00960152],\n",
       "         [-0.03842498,  0.00823998,  0.04053162, -0.0392449 ],\n",
       "         [ 0.04079253,  0.04012421, -0.04018716,  0.00984683]]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
    "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
    "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
    "\n",
    "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
    "d_model = 4\n",
    "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
    "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
    "\n",
    "emb_inp = embedding_layer_en(inp)\n",
    "emb_tar = embedding_layer_zh(tar)\n",
    "emb_inp, emb_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
    "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
    "\n",
    "inp_mask = create_padding_mask(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
    "tf.random.set_seed(9527)\n",
    "\n",
    "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
    "q = emb_inp\n",
    "k = emb_inp\n",
    "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
    "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_qk=0\n",
    "dk=0\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  global matmul_qk,dk\n",
    "  # 將 `q`、 `k` 做點積再 scale\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
    "\n",
    "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # 以注意權重對 v 做加權平均（weighted average）\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = None\n",
    "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "# 將 `q`、 `k` 做點積再 scale\n",
    "scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "# 將遮罩「加」到被丟入 softmax 前的 logits\n",
    "if mask is not None:\n",
    "  scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "# 取 softmax 是為了得到總和為 1 的比例做加權平均\n",
    "attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mask is not None:\n",
    "  scaled_attention_logits += (mask * -1e9) # 是 -1e9 不是 1e-9\n",
    "\n",
    "attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
    "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
    "\n",
    "inp_mask = create_padding_mask(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
    "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "\n",
    "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
    "look_ahead_mask = create_look_ahead_mask(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讓我們用目標語言（中文）的 batch\n",
    "# 來模擬 Decoder 處理的情況\n",
    "temp_q = temp_k = emb_tar\n",
    "temp_v = tf.cast(tf.math.greater(\n",
    "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
    "\n",
    "# 將 look_ahead_mask 放入注意函式\n",
    "_, attention_weights = scaled_dot_product_attention(\n",
    "    temp_q, temp_k, temp_v, look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_heads(x, d_model, num_heads):\n",
    "  # x.shape: (batch_size, seq_len, d_model)\n",
    "  batch_size = tf.shape(x)[0]\n",
    "  \n",
    "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
    "  assert d_model % num_heads == 0\n",
    "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度 \n",
    "  \n",
    "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
    "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
    "  # (batch_size, seq_len, num_heads, depth)\n",
    "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
    "  \n",
    "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
    "  # (batch_size, num_heads, seq_len, depth)\n",
    "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
    "  \n",
    "  return output\n",
    "\n",
    "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
    "d_model = 4\n",
    "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
    "num_heads = 2\n",
    "x = emb_inp\n",
    "\n",
    "output = split_heads(x, d_model, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實作一個執行多頭注意力機制的 keras layer\n",
    "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
    "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
    "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
    "# output.shape            == (batch_size, seq_len_q, d_model)\n",
    "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  # 在初始的時候建立一些必要參數\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
    "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
    "    \n",
    "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
    "    \n",
    "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換 \n",
    "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
    "  \n",
    "  # 這跟我們前面看過的函式有 87% 相似\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "  \n",
    "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
    "    # 輸出會多一個 head 維度\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    \n",
    "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
    "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    # (batch_size, seq_len_q, num_heads, depth)\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model)) \n",
    "    # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    # 通過最後一個線性轉換\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_inp.shape == (batch_size, seq_len, d_model)\n",
    "#               == (2, 8, 4)\n",
    "assert d_model == emb_inp.shape[-1]  == 4\n",
    "num_heads = 2\n",
    "\n",
    "# 初始化一個 multi-head attention layer\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# 簡單將 v, k, q 都設置為 `emb_inp`\n",
    "# 順便看看 padding mask 的作用。\n",
    "# 別忘記，第一個英文序列的最後兩個 tokens 是 <pad>\n",
    "v = k = q = emb_inp\n",
    "padding_mask = create_padding_mask(inp)\n",
    "\n",
    "output, attention_weights = mha(v, k, q, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  \n",
    "  # 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "seq_len = 10\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "\n",
    "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
    "ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "out = ffn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
       "       [ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
       "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
       "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
       "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 4 # FFN 的輸入輸出張量的最後一維皆為 `d_model`\n",
    "dff = 6\n",
    "\n",
    "# 建立一個小 FFN\n",
    "small_ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "# 懂子詞梗的站出來\n",
    "dummy_sentence = tf.constant([[5, 5, 6, 6], \n",
    "                              [5, 5, 6, 6], \n",
    "                              [9, 5, 2, 7], \n",
    "                              [9, 5, 2, 7],\n",
    "                              [9, 5, 2, 7]], dtype=tf.float32)\n",
    "small_ffn(dummy_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA & FFN\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  # Transformer 論文內預設 dropout rate 為 0.1\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    # layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    # 一樣，一個 sub-layer 一個 dropout layer\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  # 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同\n",
    "  def call(self, x, training, mask):\n",
    "    # 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)\n",
    "    # attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)\n",
    "    \n",
    "    # sub-layer 1: MHA\n",
    "    # Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己\n",
    "    # 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 <pad> token\n",
    "    attn_output, attn = self.mha(x, x, x, mask)  \n",
    "    attn_output = self.dropout1(attn_output, training=training) \n",
    "    out1 = self.layernorm1(x + attn_output)  \n",
    "    \n",
    "    # sub-layer 2: FFN\n",
    "    ffn_output = self.ffn(out1) \n",
    "    ffn_output = self.dropout2(ffn_output, training=training)  # 記得 training\n",
    "    out2 = self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 之後可以調的超參數。這邊為了 demo 設小一點\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "\n",
    "# 新建一個使用上述參數的 Encoder Layer\n",
    "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
    "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
    "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "assert emb_inp.shape == enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 裡頭會有 N 個 DecoderLayer，\n",
    "# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA & FFN\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    # 3 個 sub-layers 的主角們\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    # 定義每個 sub-layer 用的 LayerNorm\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    # 定義每個 sub-layer 用的 Dropout\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           combined_mask, inp_padding_mask):\n",
    "    # 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)\n",
    "    # enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)\n",
    "    # attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)\n",
    "    # attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "\n",
    "    # sub-layer 1: Decoder layer 自己對輸出序列做注意力。\n",
    "    # 我們同時需要 look ahead mask 以及輸出序列的 padding mask \n",
    "    # 來避免前面已生成的子詞關注到未來的子詞以及 <pad>\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    # sub-layer 2: Decoder layer 關注 Encoder 的最後輸出\n",
    "    # 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 <pad>\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    # sub-layer 3: FFN 部分跟 Encoder layer 完全一樣\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    # 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_padding_mask = create_padding_mask(tar)\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
    "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 超參數\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
    "\n",
    "# 來源、目標語言的序列都需要 padding mask\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar)\n",
    "\n",
    "# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
    "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算\n",
    "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
    "    emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
       "          0.99998724,  0.99998814],\n",
       "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
       "          0.9999867 ,  0.9999876 ],\n",
       "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
       "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下直接參考 TensorFlow 官方 tutorial \n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  sines = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  cosines = np.cos(angle_rads[:, 1::2])\n",
    "  \n",
    "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "  \n",
    "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "seq_len = 50\n",
    "d_model = 512\n",
    "\n",
    "pos_encoding = positional_encoding(seq_len, d_model)\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
    "  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
    "  # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "    \n",
    "    # 建立 `num_layers` 個 EncoderLayers\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "    # 輸入的 x.shape == (batch_size, input_seq_len)\n",
    "    # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
    "    input_seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
    "    # 再加上對應長度的位置編碼\n",
    "    x = self.embedding(x)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :input_seq_len, :]\n",
    "\n",
    "    # 對 embedding 跟位置編碼的總合做 regularization\n",
    "    # 這在 Decoder 也會做\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    # 通過 N 個 EncoderLayer 做編碼\n",
    "    for i, enc_layer in enumerate(self.enc_layers):\n",
    "      x = enc_layer(x, training, mask)\n",
    "      # 以下只是用來 demo EncoderLayer outputs\n",
    "      #print('-' * 20)\n",
    "      #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
    "      \n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "num_layers = 2 # 2 層的 Encoder\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2 # 記得加上 <start>, <end>\n",
    "\n",
    "# 初始化一個 Encoder\n",
    "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
    "\n",
    "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
    "enc_out = encoder(inp, training=False, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    # 為中文（目標語言）建立詞嵌入層\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "  # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
    "  def call(self, x, enc_output, training, \n",
    "           combined_mask, inp_padding_mask):\n",
    "    \n",
    "    tar_seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
    "    \n",
    "    # 這邊跟 Encoder 做的事情完全一樣\n",
    "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    \n",
    "    for i, dec_layer in enumerate(self.dec_layers):\n",
    "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
    "                                    combined_mask, inp_padding_mask)\n",
    "      \n",
    "      # 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察\n",
    "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, tar_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_layer1_block1.shape: (2, 2, 10, 10)\n",
      "decoder_layer1_block2.shape: (2, 2, 10, 8)\n",
      "decoder_layer2_block1.shape: (2, 2, 10, 10)\n",
      "decoder_layer2_block2.shape: (2, 2, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "# 超參數\n",
    "num_layers = 2 # 2 層的 Decoder\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
    "\n",
    "# 遮罩\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar)\n",
    "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
    "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 初始化一個 Decoder\n",
    "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
    "\n",
    "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
    "dec_out, attn = decoder(tar, enc_out, training=False, \n",
    "                        combined_mask=combined_mask,\n",
    "                        inp_padding_mask=inp_padding_mask)\n",
    "for block_name, attn_weights in attn.items():\n",
    "  print(f\"{block_name}.shape: {attn_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型\n",
    "class Transformer(tf.keras.Model):\n",
    "  # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, rate)\n",
    "    # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "  \n",
    "  # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
    "  # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           combined_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
    "    \n",
    "    # 將 Decoder 輸出通過最後一個 linear layer\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "num_layers = 1\n",
    "d_model = 4\n",
    "num_heads = 2\n",
    "dff = 8\n",
    "\n",
    "# + 2 是為了 <start> & <end> token\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
    "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
    "\n",
    "# 重點中的重點。訓練時用前一個字來預測下一個中文字\n",
    "tar_inp = tar[:, :-1]\n",
    "tar_real = tar[:, 1:]\n",
    "\n",
    "# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一\n",
    "inp_padding_mask = create_padding_mask(inp)\n",
    "tar_padding_mask = create_padding_mask(tar_inp)\n",
    "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
    "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
    "\n",
    "# 初始化我們的第一個 transformer\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
    "                          input_vocab_size, output_vocab_size)\n",
    "\n",
    "# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果\n",
    "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask, \n",
    "                                        combined_mask, inp_padding_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label\n",
    "real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)\n",
    "pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)\n",
    "loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  # 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 \n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  # 照樣計算所有位置的 cross entropy 但不加總\n",
    "  loss_ = loss_object(real, pred)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask  # 只計算非 <pad> 位置的損失 \n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "num_layers = 4 \n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
    "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
    "dropout_rate = 0.1  # 預設值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  # 論文預設 `warmup_steps` = 4000\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "  \n",
    "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
    "# Adam opt. 的參數都跟論文相同\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models = [128, 256, 512]\n",
    "warmup_steps = [1000 * i for i in range(1, 4)]\n",
    "\n",
    "schedules = []\n",
    "labels = []\n",
    "colors = [\"blue\", \"red\", \"black\"]\n",
    "for d in d_models:\n",
    "  schedules += [CustomSchedule(d, s) for s in warmup_steps]\n",
    "  labels += [f\"d_model: {d}, warm: {s}\" for s in warmup_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒找到 checkpoint，從頭訓練。\n"
     ]
    }
   ],
   "source": [
    "train_perc = 20\n",
    "val_prec = 1\n",
    "drop_prec = 100 - train_perc - val_prec\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
    "\n",
    "# 方便比較不同實驗/ 不同超參數設定的結果\n",
    "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
    "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
    "log_dir = os.path.join(log_dir, run_id)\n",
    "\n",
    "# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
    "# 一般來說你會想存下模型以及 optimizer 的狀態\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
    "# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  \n",
    "  # 用來確認之前訓練多少 epochs 了\n",
    "  last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "  print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
    "else:\n",
    "  last_epoch = 0\n",
    "  print(\"沒找到 checkpoint，從頭訓練。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為 Transformer 的 Encoder / Decoder 準備遮罩\n",
    "def create_masks(inp, tar):\n",
    "  # 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 \n",
    "  # 關注 Encoder 輸出序列用的\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Decoder layer 的 MHA1 在做自注意力機制用的\n",
    "  # `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
    "def train_step(inp, tar):\n",
    "  # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  # 建立 3 個遮罩\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
    "  with tf.GradientTape() as tape:\n",
    "    # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
    "def train_step(inp, tar):\n",
    "  # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  # 建立 3 個遮罩\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
    "  with tf.GradientTape() as tape:\n",
    "    # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此超參數組合的 Transformer 已經訓練 0 epochs。\n",
      "剩餘 epochs：-30\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function train_step at 0x00000203D7D73CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function train_step at 0x00000203D7D73CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 1 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-1\n",
      "Epoch 1 Loss 5.1826 Accuracy 0.0219\n",
      "Time taken for 1 epoch: 454.5733530521393 secs\n",
      "\n",
      "Saving checkpoint for epoch 2 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-2\n",
      "Epoch 2 Loss 4.2424 Accuracy 0.0606\n",
      "Time taken for 1 epoch: 396.7438747882843 secs\n",
      "\n",
      "Saving checkpoint for epoch 3 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-3\n",
      "Epoch 3 Loss 3.7403 Accuracy 0.0991\n",
      "Time taken for 1 epoch: 473.05635166168213 secs\n",
      "\n",
      "Saving checkpoint for epoch 4 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-4\n",
      "Epoch 4 Loss 3.2621 Accuracy 0.1514\n",
      "Time taken for 1 epoch: 386.00700759887695 secs\n",
      "\n",
      "Saving checkpoint for epoch 5 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-5\n",
      "Epoch 5 Loss 2.9621 Accuracy 0.1810\n",
      "Time taken for 1 epoch: 400.04305601119995 secs\n",
      "\n",
      "Saving checkpoint for epoch 6 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-6\n",
      "Epoch 6 Loss 2.7736 Accuracy 0.1986\n",
      "Time taken for 1 epoch: 376.9901831150055 secs\n",
      "\n",
      "Saving checkpoint for epoch 7 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-7\n",
      "Epoch 7 Loss 2.6334 Accuracy 0.2122\n",
      "Time taken for 1 epoch: 568.5680150985718 secs\n",
      "\n",
      "Saving checkpoint for epoch 8 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-8\n",
      "Epoch 8 Loss 2.5167 Accuracy 0.2243\n",
      "Time taken for 1 epoch: 2217.16956949234 secs\n",
      "\n",
      "Saving checkpoint for epoch 9 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-9\n",
      "Epoch 9 Loss 2.4167 Accuracy 0.2350\n",
      "Time taken for 1 epoch: 3858.096752643585 secs\n",
      "\n",
      "Saving checkpoint for epoch 10 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-10\n",
      "Epoch 10 Loss 2.3170 Accuracy 0.2466\n",
      "Time taken for 1 epoch: 2314.5384726524353 secs\n",
      "\n",
      "Saving checkpoint for epoch 11 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-11\n",
      "Epoch 11 Loss 2.2193 Accuracy 0.2577\n",
      "Time taken for 1 epoch: 3526.026778459549 secs\n",
      "\n",
      "Saving checkpoint for epoch 12 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-12\n",
      "Epoch 12 Loss 2.1263 Accuracy 0.2694\n",
      "Time taken for 1 epoch: 5754.053873300552 secs\n",
      "\n",
      "Saving checkpoint for epoch 13 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-13\n",
      "Epoch 13 Loss 2.0373 Accuracy 0.2814\n",
      "Time taken for 1 epoch: 2155.4636409282684 secs\n",
      "\n",
      "Saving checkpoint for epoch 14 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-14\n",
      "Epoch 14 Loss 1.9537 Accuracy 0.2933\n",
      "Time taken for 1 epoch: 3573.801866531372 secs\n",
      "\n",
      "Saving checkpoint for epoch 15 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-15\n",
      "Epoch 15 Loss 1.8755 Accuracy 0.3038\n",
      "Time taken for 1 epoch: 2021.1454088687897 secs\n",
      "\n",
      "Saving checkpoint for epoch 16 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-16\n",
      "Epoch 16 Loss 1.8050 Accuracy 0.3139\n",
      "Time taken for 1 epoch: 2102.265546321869 secs\n",
      "\n",
      "Saving checkpoint for epoch 17 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-17\n",
      "Epoch 17 Loss 1.7414 Accuracy 0.3229\n",
      "Time taken for 1 epoch: 4692.110122203827 secs\n",
      "\n",
      "Saving checkpoint for epoch 18 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-18\n",
      "Epoch 18 Loss 1.6782 Accuracy 0.3326\n",
      "Time taken for 1 epoch: 2160.4637944698334 secs\n",
      "\n",
      "Saving checkpoint for epoch 19 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-19\n",
      "Epoch 19 Loss 1.6080 Accuracy 0.3431\n",
      "Time taken for 1 epoch: 2948.8149280548096 secs\n",
      "\n",
      "Saving checkpoint for epoch 20 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-20\n",
      "Epoch 20 Loss 1.5456 Accuracy 0.3519\n",
      "Time taken for 1 epoch: 365.89933133125305 secs\n",
      "\n",
      "Saving checkpoint for epoch 21 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-21\n",
      "Epoch 21 Loss 1.4863 Accuracy 0.3610\n",
      "Time taken for 1 epoch: 357.1685621738434 secs\n",
      "\n",
      "Saving checkpoint for epoch 22 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-22\n",
      "Epoch 22 Loss 1.4340 Accuracy 0.3686\n",
      "Time taken for 1 epoch: 356.9187116622925 secs\n",
      "\n",
      "Saving checkpoint for epoch 23 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-23\n",
      "Epoch 23 Loss 1.3871 Accuracy 0.3757\n",
      "Time taken for 1 epoch: 712.5516493320465 secs\n",
      "\n",
      "Saving checkpoint for epoch 24 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-24\n",
      "Epoch 24 Loss 1.3442 Accuracy 0.3819\n",
      "Time taken for 1 epoch: 361.854371547699 secs\n",
      "\n",
      "Saving checkpoint for epoch 25 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-25\n",
      "Epoch 25 Loss 1.3055 Accuracy 0.3877\n",
      "Time taken for 1 epoch: 357.38259720802307 secs\n",
      "\n",
      "Saving checkpoint for epoch 26 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-26\n",
      "Epoch 26 Loss 1.2716 Accuracy 0.3925\n",
      "Time taken for 1 epoch: 357.7880277633667 secs\n",
      "\n",
      "Saving checkpoint for epoch 27 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-27\n",
      "Epoch 27 Loss 1.2364 Accuracy 0.3982\n",
      "Time taken for 1 epoch: 357.11325430870056 secs\n",
      "\n",
      "Saving checkpoint for epoch 28 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-28\n",
      "Epoch 28 Loss 1.2066 Accuracy 0.4026\n",
      "Time taken for 1 epoch: 359.2494766712189 secs\n",
      "\n",
      "Saving checkpoint for epoch 29 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-29\n",
      "Epoch 29 Loss 1.1768 Accuracy 0.4072\n",
      "Time taken for 1 epoch: 1280.5355489253998 secs\n",
      "\n",
      "Saving checkpoint for epoch 30 at nmt\\checkpoints\\4layers_128d_8heads_512dff_20train_perc\\ckpt-30\n",
      "Epoch 30 Loss 1.1525 Accuracy 0.4110\n",
      "Time taken for 1 epoch: 1546.4773645401 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定義我們要看幾遍數據集\n",
    "EPOCHS = 30\n",
    "print(f\"此超參數組合的 Transformer 已經訓練 {last_epoch} epochs。\")\n",
    "print(f\"剩餘 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
    "\n",
    "\n",
    "# 用來寫資訊到 TensorBoard，非必要但十分推薦\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs\n",
    "for epoch in range(last_epoch, EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  # 重置紀錄 TensorBoard 的 metrics\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 \n",
    "  for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
    "    \n",
    "    # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss\n",
    "    train_step(inp, tar)  \n",
    "\n",
    "  # 每個 epoch 完成就存一次檔    \n",
    "  if (epoch + 1) % 1 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  # 將 loss 以及 accuracy 寫到 TensorBoard 上\n",
    "  with summary_writer.as_default():\n",
    "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
    "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
    "  \n",
    "  print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "  print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict\n",
    "def evaluate(inp_sentence):\n",
    "  \n",
    "  # 準備英文句子前後會加上的 <start>, <end>\n",
    "  start_token = [subword_encoder_en.vocab_size]\n",
    "  end_token = [subword_encoder_en.vocab_size + 1]\n",
    "  \n",
    "  # inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列\n",
    "  # 並在前後加上 BOS / EOS\n",
    "  inp_sentence = start_token + subword_encoder_en.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
    "  # 是一個只包含一個中文 <start> token 的序列\n",
    "  decoder_input = [subword_encoder_zh.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
    "  \n",
    "  # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 每多一個生成的字就得產生新的遮罩\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "\n",
    "    # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
    "    predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
    "    if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    #將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
    "    # 下個中文字的時候關注到最新的 `predicted_id`\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Slowly and not without struggle, America began to listen.\n",
      "predicted_sentence: 而不再坐缓和没有战胜，美国开始声明。\n",
      "origin_sentence: 美国缓慢地开始倾听，但并非没有艰难曲折。\n",
      "sentence: I didn't own a Thesaurus until four years ago and I use a small Webster's dictionary that I'd bought at K-Mart for 89 cents.\n",
      "predicted_sentence: 我不要在一年前，我不要在1989年间保证，我不要为了一次坐视台湾。\n",
      "origin_sentence: 直到四年前我才有了一本词典。我使用的是用89美分在K市场里买来的一本韦氏小词典。我从来不使用单词处理程序。\n",
      "sentence: portlet, you must write three short deployment descriptors: web.xml, portlet.xml, and geronimo-web.xml. (Some of these may have been generated by your IDE.)\n",
      "predicted_sentence: 你们必须用三名单一来，用一些东西：如果你坐等到这些芝加速、食用和贿赂。\n",
      "origin_sentence: portlet 之后，您必须编写三个简短的部署描述符：web.xml、portlet.xml 和 geronimo-web.xml（这其中的一些文件可能已经由 IDE 生成）。\n",
      "sentence: Dithering is a technique that blends your colors together, making them look smoother, or just creating interesting textures.\n",
      "predicted_sentence: 有关心行动是你的技术，使它们能够从另一个生产中获得更加平等的工作。\n",
      "origin_sentence: 抖动是关于颜色混合的技术，使你的作品看起来更圆滑，或者只是创作有趣的材质。\n",
      "sentence: This paper discusses the petrologic characteristics of the coal-bearing strata under the geologic structural background of the Tertiary coal basin in Hunchun.\n",
      "predicted_sentence: 这一测字化石化使化石燃料的地质量是在地缘化的地质量的地缘政治理文化的结构。\n",
      "origin_sentence: 本文以珲春早第三纪含煤盆地的地质构违背景为依据，分析了煤系地层的岩石学特征。\n",
      "sentence: Women over 55 are pickier about their partners than at any other time in their lives.\n",
      "predicted_sentence: 女性5555岁以上，女性比其他人的生活更加重要。\n",
      "origin_sentence: 55岁以上的女人们对自己伴侣更为挑剔。\n",
      "sentence: Ruben: So, to heal (with capital letters) you need to have no predilections.\n",
      "predicted_sentence: 基因：要想实际上，你需要（你不需要）的资本人，你不需要逃脱轨道。\n",
      "origin_sentence: 所以，要“治疗“他人你必须没有任何偏好。\n",
      "sentence: The second encounter relates to my grandfather's treasure box.\n",
      "predicted_sentence: 第二个鼓励我的父亲安地逃避了我的地方。\n",
      "origin_sentence: 第二次事件跟我爷爷的宝贝匣子有关。\n",
      "sentence: Change the value for the <ejb-link> tag to MyEJB, which is the name of the EJB as defined in the ejb-jar.xml file.\n",
      "predicted_sentence: 改变了珍珠链安全的全部长委员会，在银行中都存在于ECEO的名义词。\n",
      "origin_sentence: 将 <ejb-link> 标记的值更改为 MyEJB，即在 ejb-jar.xml 文件中定义的 EJB 名称。\n",
      "sentence: One way to address these challenges would be to establish a Truth and Reconciliation Commission modeled on the experience of Muggle South Africa.\n",
      "predicted_sentence: 一个解决这些挑战的问题是建立南欧委员会和建设一个南非的经验室领导人的模式。\n",
      "origin_sentence: 解决这些挑战的途径包括依照麻瓜在南非的经验设立真相与和解委员会。\n",
      "sentence: Brain: If you don't mind, Jonathan, while you and Mr. Sun get acquainted, I'd like to check the arrangements for the meeting.\n",
      "predicted_sentence: 莫思维也不会想象，而你就像八门那样，也就像八门干扰该系统的安排签订。\n",
      "origin_sentence: 如果你不介意，Jonathan，在你和孙先生互相认识时，我先失陪，看看会议安排得如何。\n",
      "sentence: Bailee Madison plays Sally, a young girl who goes to live with her father and his girlfriend.\n",
      "predicted_sentence: 不过，在萨尔德遭遇了反对，女孩离的年轻女孩和父母的年轻女孩子。\n",
      "origin_sentence: 受托保管人麦迪逊扮演莎莉，一个年轻的女孩谁去与她同住的父亲和他的女朋友。\n",
      "sentence: Reduce blood fat, prevent thrombosis, arteriosclerosis, apoplexy and heart disease. Improve memory, nourish the brain and improve the intelligence.\n",
      "predicted_sentence: 减少血液态系统的传播已经过了，艺术和测试验室气体的日程，改变了记录和心脏病。\n",
      "origin_sentence: 降血脂，预防血栓、动脉硬化、中风和心脏病；改善记忆，健脑益智。\n",
      "sentence: Toomay said signs of community intolerance, including bumper stickers opposing same-sex marriage, also made him feel down, and he sought guidance from a school counselor after contemplating suicide.\n",
      "predicted_sentence: 自动化表明，包括与男子的同样有效的同性和参与者有关的侵犯了他们的报道。\n",
      "origin_sentence: Toomay 说到群体性不宽容的标志，其中包括保险杠贴纸里有反同性婚姻，这也让他觉得低落。 他在认真考虑过自杀后向一位学校咨询员寻求了指导。\n",
      "sentence: When you eat dinner out, reduce the temptation to clean your plate by setting aside one-third of your meal.\n",
      "predicted_sentence: 你会揭穿越恒的，减少你的废墟是设施30万名单的剑桥。\n",
      "origin_sentence: 当你在外吃晚餐的时候，把你晚餐中三分之一的食物放置在一边。\n",
      "sentence: Sang Lan is one of the best athletes in our country.\n",
      "predicted_sentence: 桑德斯文尔是一个最好的国家。\n",
      "origin_sentence: 桑兰是我国最优异的运带动之一。\n",
      "sentence: They are able to show that active peroxiredoxin 1, Prx1, an enzyme that breaks down harmful hydrogen peroxide in the cells, is required for caloric restriction to work effectively.\n",
      "predicted_sentence: 他们都能确实积极地评估1.1的神圣诞生，这个神圣诞生了一种干燥的范畴。\n",
      "origin_sentence: 他们已经证明出活性过氧化物酶1（prx1），一种能够将细胞内有害的过氧化氢分解的酶类，正是此正面效应的所需酶类。\n",
      "sentence: He went to slide upon the ice Before the ice would bear; Then he plunged in above his knees, Which made poor Simon stare.\n",
      "predicted_sentence: 他向前任枪声卷土重来；他将在他的人口中，从而不到他的穷人中赚到穷人。\n",
      "origin_sentence: 他到冰上去滑冰在冰还能支撑前； 接着他陷入水中直到膝盖， 可怜的西蒙睁大了眼。\n",
      "sentence: Miaoxiang son know the devil tricks, white three quick deployment.\n",
      "predicted_sentence: 桑德斯的罪名者知道，大家被知道这三个孩子的入狱。\n",
      "origin_sentence: 苗香儿知道了鬼子的诡计，白三部署速战速结。\n",
      "sentence: “My daughter has been banned from watching the show, ” supermodel Cindy Crawford told ShowbizSpy.\n",
      "predicted_sentence: “我的女女儿很有禁止被披露，超过西方国家的Shwakifok野蛮攻击。\n",
      "origin_sentence: 超级名模辛迪•克劳馥在接受美国ShowbizSpy网站采访时表示：“我禁止女儿看这个节目。\n",
      "sentence: \"The Chinese Super League starts in a couple of weeks and Sheffield United have asked me to go over and have a look at the coaching set-up, \" said McKinna.\n",
      "predicted_sentence: \"19/1日子里萨和麦肯锡的一些中国人都要求美国的赞扬，并在这一问题上。\n",
      "origin_sentence: “中国足球超级联赛几周之后将拉开战幕，谢菲尔德联队邀请我过去看一下它们的教练配备，”麦克金纳说道。\n",
      "sentence: On the fifteenth day of that month the Lord 's Feast of Unleavened Bread begins; for seven days you must eat bread made without yeast.\n",
      "predicted_sentence: 第五天，东京的五位超级章节约了，而不再是七星星星星星星星里的坎坷。\n",
      "origin_sentence: 这月十五日是向耶和华守的无酵节, 你们要吃无酵饼七日.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "orig = dict()\n",
    "with open('./translation2019zh/translation2019zh_valid.json', 'r', newline='', encoding=\"utf-8\") as file:\n",
    "    data = file.readline()\n",
    "    while data:\n",
    "        orig[json.loads(data)['english']] = json.loads(data)['chinese']\n",
    "        sentence=json.loads(data)['english']\n",
    "        predicted_seq, _ = evaluate(sentence)\n",
    "\n",
    "        # 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
    "        target_vocab_size = subword_encoder_zh.vocab_size\n",
    "        predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
    "        predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
    "\n",
    "        print(\"sentence:\", sentence)\n",
    "        print(\"predicted_sentence:\", predicted_sentence)\n",
    "        print(\"origin_sentence:\", orig[json.loads(data)['english']])\n",
    "        data = file.readline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
